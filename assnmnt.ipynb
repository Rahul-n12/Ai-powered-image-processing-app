{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Function to generate an image using DALL-E 3\n",
    "def generate_edited_image(image_path, prompt):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            response = client.images.generate(\n",
    "                model=\"dall-e-3\",\n",
    "                prompt=prompt,\n",
    "                size=\"1024x1024\",\n",
    "                n=1\n",
    "                )\n",
    "        print(\"DALLÂ·E API Full Response:\", response) # Print the full API response for debugging\n",
    "        image_url = response.data[0].url\n",
    "        return image_url\n",
    "    except Exception as e:\n",
    "        print(f\"Image generation failed: {e}\") # Print to console for debugging\n",
    "        return None\n",
    "     \n",
    "\n",
    "# Function to transcribe audio using OpenAI Whisper API\n",
    "def transcribe_audio(audio_file_path):\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            transcript = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file\n",
    "            )\n",
    "        return transcript.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Transcription failed: {e}\")  # Print to console\n",
    "        return None\n",
    "\n",
    "def process_inputs(audio_filepath, image_pil):\n",
    "    if audio_filepath is None or image_pil is None:\n",
    "        return \"Please upload both audio and image.\", None\n",
    "\n",
    "    if audio_filepath:\n",
    "        audio_extension = os.path.splitext(audio_filepath)[1]\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=audio_extension) as temp_audio_file:\n",
    "            with open(audio_filepath, \"rb\") as audio_file:\n",
    "                temp_audio_file.write(audio_file.read())\n",
    "\n",
    "            temp_audio_path = temp_audio_file.name\n",
    "\n",
    "        transcription = transcribe_audio(temp_audio_path)\n",
    "\n",
    "        if transcription:\n",
    "            prompt = f\"{transcription}\"\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as temp_image_file:\n",
    "                image_rgba = image_pil.convert(\"RGBA\")  # Convert to RGBA\n",
    "                image_rgba.save(temp_image_file, format=\"PNG\")\n",
    "                temp_image_path = temp_image_file.name \n",
    "\n",
    "            image_url = generate_edited_image(temp_image_path, prompt)\n",
    "\n",
    "            if image_url:\n",
    "                try:\n",
    "                    response = requests.get(image_url, stream=True)\n",
    "                    response.raise_for_status()\n",
    "                    image_bytes = BytesIO()\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        image_bytes.write(chunk)\n",
    "                    image_bytes.seek(0)\n",
    "\n",
    "                    generated_image = Image.open (image_bytes)\n",
    "                    generated_image = generated_image.resize((512, 512), Image.LANCZOS)\n",
    "                    generated_image_np = np.array(generated_image) # Convert to numpy array\n",
    "\n",
    "                    os.remove(temp_image_path)  # Remove initial image after edit\n",
    "                    os.remove(temp_audio_path)\n",
    "\n",
    "\n",
    "                    return \"Success!\", generated_image_np\n",
    "                \n",
    "                except Exception as e:\n",
    "                    return f\"Error displaying image: {e}\", None\n",
    "            else:\n",
    "                return \"Image edit failed.\", None\n",
    "\n",
    "            \n",
    "        os.remove(temp_audio_path)\n",
    "\n",
    "    return \"\", None\n",
    "\n",
    "\n",
    "\n",
    "# Define the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload Audio\")\n",
    "    image_input = gr.Image(type=\"pil\", label=\"Upload Initial Image (<4MB)\") # Changed to type=\"pil\"\n",
    "    output_message = gr.Textbox(label=\"Message\") # For displaying messages\n",
    "    image_output = gr.Image(type= \"numpy\", label=\"Generated Image\")\n",
    "    btn = gr.Button(\"Generate\")\n",
    "    btn.click(\n",
    "        fn=process_inputs,\n",
    "        inputs=[audio_input, image_input], # Pass both inputs to the function\n",
    "        outputs=[output_message, image_output] # Output the message and the image\n",
    "    )\n",
    "\n",
    "demo.launch(share=True, server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
